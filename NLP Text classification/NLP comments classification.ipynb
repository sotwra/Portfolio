{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ текстов на токсичность\n",
    "\n",
    "Интернет-магазин запускает новый сервис: пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах.   \n",
    "Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "**Задача**  \n",
    "- Создать модель для классификации комментариев на позитивные и негативные    \n",
    "- Модель должна обеспечивать значение метрики качества *F1* не меньше 0.75   \n",
    "- Имеет значение ресурсоёмкость решения: \n",
    "    - сколько требуется времени для подготовки модели к инфренсу? \n",
    "    - требуются ли ресурсы GPU для решения задачи?\n",
    "\n",
    "**Способ решения**  \n",
    "\n",
    "Исследовать несколько сочетаний моделей и способов предобработки текста и предложить в продакшн оптимальный вариант.  \n",
    "С заказчиком согласовано исследование следующих моделей:\n",
    "- Логистическая регрессия\n",
    "- Бустинг CatBoost\n",
    "\n",
    "А также кодирование текста при помощи: \n",
    "- Методики TF-IDF\n",
    "- Предобученной нейросети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных\n",
    "Имеется набор размеченных данных по токсичности правок.\n",
    "   \n",
    "Данные находятся в файле `toxic_comments.csv`.   \n",
    "Столбец *text* в нём содержит текст комментария, а *toxic* — бинарный целевой признак (1/0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План работы\n",
    "1. Загрузить и исследовать данные:\n",
    "    - Изучить данные, проверить их на предмет пропусков, аномалий и дубликатов\n",
    "    - Исследовать данные на дисбаланс классов\n",
    "\n",
    "1. Предобработать данные, подготовить отдельные датасеты для моделирования:\n",
    "    - Очистить данные от спец. символов, цифр, знаков препинания и др.\n",
    "    - Повторно проверить на аномалии\n",
    "    - Разбить данные на обучающую и тестовую(20%) выборки \n",
    "    - Сделать векторизацию тестов по TF-IDF:\n",
    "        - лемматизировать текстовые данные\n",
    "        - удалить стоп-слова и сгенерировать дополнительные признаки с использованием:\n",
    "            - униграмм\n",
    "            - диграмм\n",
    "    - Подобрать подходящую под задачу предобученную нейросеть из сообщества Hugging Face и сгенерировать эмбединги текстов    \n",
    "\n",
    "1.  Исследовать модели с использованием обозначенных выше способов предобработки:  \n",
    "    - Обучить модели с подбором гиперпараметров на кросс-валидации:\n",
    "        - Логистическая регрессия:\n",
    "            - TF-IDF на униграммах\n",
    "            - TF-IDF на диграммах\n",
    "            - эмбединги от нейросети  \n",
    "        - Бустинг CatBoost:\n",
    "            - очищенный текст без векторизации *(i)*\n",
    "            - эмбединги от нейросети\n",
    "    - Сделать сводую таблицу результатов и выбрать оптимальную модель и тип предобработки\n",
    "\n",
    "1. Тестирование\n",
    "    - Сгенерировать \"дамми\" модель для проверки оптимальной модели на адекватность\n",
    "    - Проверить оптимальную модель и способ предобработки на тестовых данных\n",
    "\n",
    "1. Составить выводы и рекомендации \n",
    "\n",
    "*(i) Модель Catboost имеет встроенные средства векторизации текстов - можно подавать текстовые признаки без кодирования.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка и первичный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовые и служебные библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Прогресс выполнения и время работы\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from time import time\n",
    "\n",
    "# Работа с текстом\n",
    "\n",
    "#Нейросети\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "#Борьба с регулярными выражениями\n",
    "import re\n",
    "\n",
    "# Лемматизация\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Стоп-слова для исключения и леммация англ\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# Класс для генерации признаков как матрицы TF-IDF для слов\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Модели \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Метрики, разделялки и впомогательные для моделей\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройки и константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "RANDOM_STATE = 12345\n",
    "\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пользовательские функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистка текста\n",
    "- Удаляет все спец. символы, знаки препинания и лишние пробелы \n",
    "- Приводит данные к единому регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_clear_text_lower(text):\n",
    "    t = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    t = \" \".join(t.split())\n",
    "    t = t.lower()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация\n",
    "- Использует быстрый лемматизатор Snowball для английского языка\n",
    "\n",
    "*Пробовал лемматизатор из Spacy, работает на порядки медленнее, а результат по метрике +/- тот же.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_lemmatize_engl(text):\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    t = list(text.split())\n",
    "    result = []\n",
    "    for a in t:\n",
    "        result.append(stemmer.stem(a))\n",
    "    result = ' '.join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация эмбедингов с помощью предобученной нейросети\n",
    "- Можно задать имя нейросети из комьюнити Hugging Face\n",
    "- По умолчанию - BERT для токсичных комментариев, т.к. эта нейросеть как раз под задачу данного проекта\n",
    "- Работает на CPU или GPU. По умолчанию GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_get_embedings(series_to_encode, run_on_gpu=True, hugface_model_name:str='unitary/toxic-bert', batch_limit=100):\n",
    "\n",
    "    # Сохранение исходного индекса df/series\n",
    "    series_to_encode_index = series_to_encode.index\n",
    "\n",
    "    # Загрузка модели и её токенизатора\n",
    "    tokenizer = BertTokenizer.from_pretrained(hugface_model_name)\n",
    "    model = BertModel.from_pretrained(hugface_model_name)\n",
    "\n",
    "    # Токенизация и кодирование\n",
    "    tokenized_texts = tokenizer.batch_encode_plus(\n",
    "                                series_to_encode,\n",
    "                                padding=True,\n",
    "                                truncation=True,\n",
    "                                return_tensors='pt',\n",
    "                                add_special_tokens=True)\n",
    "    input_ids = tokenized_texts['input_ids']\n",
    "    attention_mask = tokenized_texts['attention_mask']\n",
    "\n",
    "    # Найдём максимальный размера батча (делитель без остатка) в заданном лимите \n",
    "    while len(series_to_encode) % batch_limit != 0:\n",
    "        batch_limit -= 1\n",
    "\n",
    "    batch_size = batch_limit\n",
    "    embeddings = []\n",
    "\n",
    "    # Если работаем на GPU, то предварительно переводим модель и все тензоры на GPU\n",
    "    # Предварительно проверим, доступна ли работа на GPU\n",
    "    if run_on_gpu:\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU: {torch.cuda.get_device_name(0)} is available. Running on GPU\")\n",
    "\n",
    "            for i in tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "                model = model.to('cuda')\n",
    "                batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).to('cuda')\n",
    "                attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).to('cuda')\n",
    "\n",
    "                # Генерация эмбедингов\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(batch, attention_mask=attention_mask_batch)\n",
    "                    embeddings_batch = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "                    embeddings.append(embeddings_batch)\n",
    "                \n",
    "        torch.cuda.empty_cache() # Обязательно очистить кэш GPU, иначе возможны сбои kernel           \n",
    "\n",
    "    else:\n",
    "        print(\"Training will run on CPU.\")\n",
    "        for i in tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "            batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)])\n",
    "            attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "            # Генерация эмбедингов\n",
    "            with torch.no_grad():\n",
    "                outputs = model(batch, attention_mask=attention_mask_batch)\n",
    "                embeddings_batch = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "                embeddings.append(embeddings_batch)\n",
    "\n",
    "    return pd.DataFrame(np.concatenate(embeddings), index=series_to_encode_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и знакомство с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('toxic_comments.csv', index_col='Unnamed: 0')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество дубликатов: 0\n"
     ]
    }
   ],
   "source": [
    "print('Количество дубликатов:', df['text'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пустых текстовых записей: 0\n"
     ]
    }
   ],
   "source": [
    "print('Количество пустых текстовых записей:', df.loc[(df['text']=='')|(df['text']==' ')]['text'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя длинна текста: 394\n",
      "Максимальная длинна текста: 4521\n"
     ]
    }
   ],
   "source": [
    "print('Средняя длинна текста:', round(df['text'].str.len().mean()))\n",
    "print('Максимальная длинна текста:', len(df['text'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследование баланса классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля нетоксичных записей 89.8 %\n",
      "Доля токсичных записей 10.2 %\n"
     ]
    }
   ],
   "source": [
    "class_balance = df['toxic'].value_counts(normalize=True).round(3)\n",
    "print('Доля нетоксичных записей', class_balance[0]*100, '%')\n",
    "print('Доля токсичных записей', class_balance[1]*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы первичного анализа данных**\n",
    "- Данных (159 тыс. строк) достаточно для тестирования выбранных типов моделей и кодирования\n",
    "- Пропусков и дубликатов нет\n",
    "- Текстовый массив затруднительно обработать простыми аголоритмами, т.к. макс. длинна текста 4500, а средняя длинна 394 символа\n",
    "- Сильный дисбаланс классов (9 к 1). Потребуется учитывать это при использовании Логистической регрессии\n",
    "- Текстовые данные \"грязные\", есть спец символы (\\n и др.), разный регистр и т.д.\n",
    "- Текст не лемматизирован"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(func_clear_text_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим не образовались ли пустые записи и/или состоящие из пробела после очистки текста.  \n",
    "Такое может быть, если текст состоял только из пробелов и/или спец. символов.  \n",
    "\n",
    "Если таких наблюдений немного, то можно их отбросить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пустых текстовых записей: 11\n"
     ]
    }
   ],
   "source": [
    "print('Количество пустых текстовых записей:', df.loc[(df['text']=='')|(df['text']==' ')]['text'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(df['text']!='')&(df['text']!=' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение данных на обучающую и тестовую (20%) выборки\n",
    "- Т.к. предобработка будет отличаться в зависимости от типа модели, заранее разобьём данные\n",
    "- Тестовые данные предобработаем под потребности итоговой модели, которую будем на них проверять\n",
    "- Дисбаланс классов при разбиении не учитываем - **нет гарантии**, что на вновь поступающих данных он будет таким же"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train['text']\n",
    "y_train = df_train['toxic']\n",
    "\n",
    "x_test = df_test['text']\n",
    "y_test = df_test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация по TF-IDF\n",
    "Лемматизируем текст и подготовим датасеты с генерацией признаков по TF-IDF:\n",
    "- с униграммами\n",
    "- с диграммами  \n",
    "\n",
    "Запишем время, необходимое для этих операций, чтобы потом учесть его в общей скорости обучения соотв. моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время лемматизации: 34.3 c\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "x_train_lemmatized = x_train.copy()\n",
    "x_train_lemmatized = x_train_lemmatized.apply(func_lemmatize_engl)\n",
    "\n",
    "end = time()\n",
    "\n",
    "time_lemmatization = end - start\n",
    "\n",
    "print('Время лемматизации:', time_lemmatization.__round__(1), 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF с униграммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество полученных признаков: 115213\n",
      "Время генерации: 6.4 c\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "vectorizer_uni = TfidfVectorizer(stop_words=stopwords) \n",
    "vectorizer_uni.fit(x_train_lemmatized)\n",
    "x_train_tfidf_uni = vectorizer_uni.transform(x_train_lemmatized)\n",
    "\n",
    "end = time()\n",
    "\n",
    "time_tfidf_uni = end - start\n",
    "\n",
    "print(\"Количество полученных признаков:\", x_train_tfidf_uni.shape[1])\n",
    "print(\"Время генерации:\", time_tfidf_uni.__round__(1), 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF с диграммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество полученных признаков: 1867778\n",
      "Время генерации: 14.1 с\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "vectorizer_di = TfidfVectorizer(stop_words=stopwords, ngram_range=(2,2)) \n",
    "vectorizer_di.fit(x_train_lemmatized)\n",
    "x_train_tfidf_di = vectorizer_di.transform(x_train_lemmatized)\n",
    "\n",
    "end = time()\n",
    "\n",
    "time_tfidf_di = end - start\n",
    "\n",
    "print(\"Количество полученных признаков:\", x_train_tfidf_di.shape[1])\n",
    "print(\"Время генерации:\", time_tfidf_di.__round__(1), 'с')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот оно как. Наблюдаем взрыв признаков при переходе на диграммы.   \n",
    "Число признаков увеличилось в 16 раз до 1,8+ млн.   \n",
    "Для дальнейшей работы моделей это не лучший вариант из-за слишком долгого времени работы, особенно с подбором гиперпараметров.\n",
    "\n",
    "Ограничим число признаков при генерации 1 млн. Векторизатор отберёт их по частоте встречаемости в корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество полученных признаков: 1000000\n",
      "Время генерации: 14.6 с\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "vectorizer_di = TfidfVectorizer(stop_words=stopwords, ngram_range=(2,2), max_features=1000000) \n",
    "vectorizer_di.fit(x_train_lemmatized)\n",
    "x_train_tfidf_di = vectorizer_di.transform(x_train_lemmatized)\n",
    "\n",
    "end = time()\n",
    "\n",
    "time_tfidf_di = end - start\n",
    "\n",
    "print(\"Количество полученных признаков:\", x_train_tfidf_di.shape[1])\n",
    "print(\"Время генерации:\", time_tfidf_di.__round__(1), 'с')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получение эмбедингов с помощью нейросети BERT\n",
    "Используем данные, очищенные от спец символов, цифр, знаков препинания.  \n",
    "Не делаем лематизацию и удаление стоп-слов, т.к. это может помешать нейросети оценить контекст.\n",
    "\n",
    "Используем предобученную нейросеть специализующуюся на токсичных комментариях.\n",
    "\n",
    "Данных много. Прежде, чем перейти к расчёту эмбедингов, оценим примерное время для выполнения задачи на CPU и GPU.  \n",
    "**Время GPU существенно дороже, если время выполнения позволяет, то лучше обойтись CPU**  \n",
    "\n",
    "Сделаем эмбединги для 500 текстовых записей и расчитаем время на обработку всего корпуса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка времени выполнения задачи на CPU и GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will run on CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:10<00:00, 50.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расчётное время для получения эмбедингов на CPU: 535.0 минут\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "embedings_trial = func_get_embedings(x_train[0:500], run_on_gpu=False)\n",
    "\n",
    "end = time()\n",
    "\n",
    "time_estimation_embeddings_cpu = round((end - start) * (len(x_train) / 1000) / 60, 0)   \n",
    "del embedings_trial\n",
    "\n",
    "print(\"Расчётное время для получения эмбедингов на CPU:\", time_estimation_embeddings_cpu, 'минут')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 3070 Laptop GPU is available. Running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расчётное время для получения эмбедингов на видеокарте (GPU): 26.0 минут\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "embedings_trial = func_get_embedings(x_train[0:500], run_on_gpu=True)\n",
    "\n",
    "end = time()\n",
    "\n",
    "time_estimation_embeddings_gpu = round((end - start) * (len(x_train) / 1000) / 60, 0)   \n",
    "\n",
    "del embedings_trial\n",
    "\n",
    "print(\"Расчётное время для получения эмбедингов на видеокарте (GPU):\", time_estimation_embeddings_gpu, 'минут')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**   \n",
    "- Будем работать на GPU, т.к. расчётно потребуется всего ок. 30 мин  \n",
    "- Время получения эмбедингов на CPU слишком долгое - в 20 раз больше чем на GPU (590+ мин или ок. 10 часов) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Получение эмбедингов для обучающей выборки\n",
    "*Если эмбединги ранее уже были получены на этапе разработки, то загрузим из файла.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    x_train_embedded = pd.read_pickle('x_train_embedded.pkl')    \n",
    "    time_fact_embeddings = 2936.13 # Замерено ранее\n",
    "    \n",
    "except:    \n",
    "    start = time()\n",
    "\n",
    "    x_train_embedded = func_get_embedings(x_train, run_on_gpu=True)\n",
    "    x_train_embedded.to_pickle('x_train_embedded.pkl')\n",
    "\n",
    "    end = time()\n",
    "\n",
    "    time_fact_embeddings = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Моделирование\n",
    "Проверим различные сочетания моделей и предобработки данных на кросс-валидации с подбором гиперпараметров.  \n",
    "Подбор гиперпараметров может существенно повлиять на точность Логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим единую сетку для подбора гиперпараметров всех подвидов модели.\n",
    "- В данных сильный дисбаланс классов: учтём это и поставим настройку 'classifier__class_weight' = 'balanced'\n",
    "- Используем алгоритм 'saga', он лучше подходят для больших датасетов + поддерживает смешанную регуляризацию ElasticNet\n",
    "- Для повышения точности модели важно оптимизировать параметры регуляризации весов:  \n",
    "    - Для этого используем смешанную регуляризацию Elasticnet + подбор коэф. l1/l2\n",
    "    - Инверсию регуляризации (параметр 'C')\n",
    "\n",
    "Датасет достаточно большой, а также хочется проверить широкий круг гиперпараметров.   \n",
    "Чтобы сэкономить время проведём подбор гиперпараметров в 2 этапа:\n",
    "- Сузим круг поиска за счёт предварительного случайного поиска по сетке параметров с заданным числом итераций\n",
    "- Проведём поиск по более узкой сетке для каждой модели   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0 Случайный подбор гиперпараметров Логистической регрессии для сужения сетки поиска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходная широкая сетка гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_LogReg_long = [{'solver': ['saga'],                # default 'lbfgs'\n",
    "                       'class_weight': ['balanced'],      # default None\n",
    "                       'penalty':['elasticnet'],          # default l2\n",
    "                       'l1_ratio':[0, 0.1, 0.3, 0.7, 1],  # default None\n",
    "                       'max_iter': [100, 150],            # default 100\n",
    "                       'C': range(1, 10)                  # default 1.0\n",
    "                      }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Лучшая метрика F1 на кросс-валидации: 0.767\n",
      "Лучшие гиперпараметры: {'solver': 'saga', 'penalty': 'elasticnet', 'max_iter': 150, 'l1_ratio': 1, 'class_weight': 'balanced', 'C': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\UpdatedProject Venv on Python 3.12.2\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_LogReg_try = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model_LogReg_try, param_distributions=params_LogReg_long, \n",
    "                          scoring='f1', cv=2, n_iter=25, n_jobs=-1, verbose=0) \n",
    "grid.fit(X=x_train_tfidf_uni, y=y_train)\n",
    "\n",
    "best_params_LogReg_try = grid.best_params_\n",
    "best_metric_LogReg_try = grid.best_score_\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Лучшая метрика F1 на кросс-валидации:', best_metric_LogReg_try.__round__(3))\n",
    "print('Лучшие гиперпараметры:', best_params_LogReg_try)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая сокращенная сетка для поиска гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_LogReg = [{'solver': ['saga'],           # default 'lbfgs'\n",
    "                  'class_weight': ['balanced'], # default None\n",
    "                  'penalty':['elasticnet'],     # default l2\n",
    "                  'l1_ratio':[0.7, 0.8, 0.9],   # default None\n",
    "                  'max_iter': [150],            # default 100\n",
    "                  'C': [2, 5, 9]                # default 1.0\n",
    "                }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Логистическая регрессия + векторизация по TF-IDF с униграммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая метрика F1 на кросс-валидации: 0.772\n",
      "Лучшие гиперпараметры: {'C': 2, 'class_weight': 'balanced', 'l1_ratio': 0.7, 'max_iter': 150, 'penalty': 'elasticnet', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\UpdatedProject Venv on Python 3.12.2\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_LogReg_tfidf_uni = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "grid = GridSearchCV(estimator=model_LogReg_tfidf_uni, param_grid=params_LogReg, scoring='f1', cv=2, n_jobs=-1, verbose=0) \n",
    "grid.fit(X=x_train_tfidf_uni, y=y_train)\n",
    "\n",
    "best_params_LogReg_tfidf_uni = grid.best_params_\n",
    "best_metric_LogReg_tfidf_uni = grid.best_score_\n",
    "\n",
    "print('Лучшая метрика F1 на кросс-валидации:', best_metric_LogReg_tfidf_uni.__round__(3))\n",
    "print('Лучшие гиперпараметры:', best_params_LogReg_tfidf_uni) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с подобранными гиперпараметрами на всех обучающих данных и засечём время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения: 245.536 c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\UpdatedProject Venv on Python 3.12.2\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "best_model_LogReg_tfidf_uni = LogisticRegression(random_state=RANDOM_STATE, **best_params_LogReg_tfidf_uni)\n",
    "best_model_LogReg_tfidf_uni.fit(x_train_tfidf_uni, y_train)\n",
    "\n",
    "end = time()\n",
    "\n",
    "time_fit_LogReg_tfidf_uni = end - start\n",
    "print('Время обучения:', time_fit_LogReg_tfidf_uni.__round__(3), 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Логистическая регрессия + векторизация по TF-IDF с диграммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая метрика F1 на кросс-валидации: 0.511\n",
      "Лучшие гиперпараметры: {'C': 9, 'class_weight': 'balanced', 'l1_ratio': 0.9, 'max_iter': 150, 'penalty': 'elasticnet', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\UpdatedProject Venv on Python 3.12.2\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_LogReg_tfidf_di = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "grid = GridSearchCV(estimator=model_LogReg_tfidf_di, param_grid=params_LogReg, scoring='f1', cv=2, n_jobs=-1, verbose=0) \n",
    "grid.fit(X=x_train_tfidf_di, y=y_train)\n",
    "\n",
    "best_params_LogReg_tfidf_di = grid.best_params_\n",
    "best_metric_LogReg_tfidf_di = grid.best_score_\n",
    "\n",
    "print('Лучшая метрика F1 на кросс-валидации:', best_metric_LogReg_tfidf_di.__round__(3))\n",
    "print('Лучшие гиперпараметры:', best_params_LogReg_tfidf_di)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с подобранными гиперпараметрами на всех обучающих данных и засечём время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения: 1424.63 c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\UpdatedProject Venv on Python 3.12.2\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "best_model_LogReg_tfidf_di = LogisticRegression(random_state=RANDOM_STATE, **best_params_LogReg_tfidf_di)\n",
    "best_model_LogReg_tfidf_di.fit(x_train_tfidf_di, y_train)\n",
    "\n",
    "end = time()\n",
    "\n",
    "time_fit_LogReg_tfidf_di = end - start\n",
    "print('Время обучения:', time_fit_LogReg_tfidf_di.__round__(2), 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Логистическая регрессия + эмбединги от нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая метрика F1 на кросс-валидации: 0.89\n",
      "Лучшие гиперпараметры: {'C': 5, 'class_weight': 'balanced', 'l1_ratio': 0.8, 'max_iter': 150, 'penalty': 'elasticnet', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\UpdatedProject Venv on Python 3.12.2\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_LogReg_embeddings = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "grid = GridSearchCV(estimator=model_LogReg_embeddings, param_grid=params_LogReg, scoring='f1', cv=2, n_jobs=-1, verbose=0) \n",
    "grid.fit(X=x_train_embedded, y=y_train) \n",
    "\n",
    "best_params_LogReg_embeddings = grid.best_params_\n",
    "best_metric_LogReg_embeddings = grid.best_score_\n",
    "\n",
    "print('Лучшая метрика F1 на кросс-валидации:', best_metric_LogReg_embeddings.__round__(2))\n",
    "print('Лучшие гиперпараметры:', best_params_LogReg_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с подобранными гиперпараметрами на всех обучающих данных и засечём время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения: 116.08 c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\UpdatedProject Venv on Python 3.12.2\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "best_model_LogReg_embeddings = LogisticRegression(random_state=RANDOM_STATE, **best_params_LogReg_embeddings)\n",
    "best_model_LogReg_embeddings.fit(x_train_embedded, y_train)\n",
    "\n",
    "end = time()\n",
    "\n",
    "time_fit_LogReg_embeddings = end - start\n",
    "print('Время обучения:', time_fit_LogReg_embeddings.__round__(2), 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Бустинг CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В CatBoost встроены токенизатор и методы векторизации, поэтому мало смысла использовать отдельную векторизацию по TF-IDF.  \n",
    "Попробуем подать на вход два варианта предобработки:\n",
    "- только с базовой очисткой текста\n",
    "- эмбединги, полученные от нейросети BERT\n",
    "\n",
    "Модель хорошо работает из \"коробки\", но достаточно долго обучается.   \n",
    "По опыту прошлых проектов, подбор гиперпараметров не сильно влияет на результаты модели. \n",
    "\n",
    "Перебрём минимальное число гиперпараметров, которые могут немного улучшить результат (l2 регуляризацию и количество итераций). \n",
    "\n",
    "*Используем GPU для ускорения работы.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_CatBoost = { 'n_estimators': [1000, 1200],     # default 1000 \n",
    "                    'l2_leaf_reg': [3, 7, 10]         # default 3 \n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 CatBoost + очищенный текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "\n",
      "Лучшая метрика F1 на кросс-валидации: 0.773\n",
      "Лучшие гиперпараметры: {'l2_leaf_reg': 3, 'n_estimators': 1200}\n"
     ]
    }
   ],
   "source": [
    "x_train_DF = pd.DataFrame(x_train, columns=['text']) # техническое преобразование в датафрейм для работы модели\n",
    "\n",
    "model_Cat_clean_text = CatBoostClassifier(random_state=RANDOM_STATE, eval_metric='F1', task_type='GPU')\n",
    "\n",
    "grid = GridSearchCV(estimator=model_Cat_clean_text, param_grid=params_CatBoost, scoring='f1', cv=2, verbose=0)\n",
    "grid.fit(X=x_train_DF, y=y_train, text_features=['text'], silent=True)\n",
    "\n",
    "best_params_Cat_clean_text = grid.best_params_\n",
    "best_metric_Cat_clean_text = grid.best_score_\n",
    "\n",
    "print('-------------------------------------')\n",
    "print()\n",
    "print('Лучшая метрика F1 на кросс-валидации:', best_metric_Cat_clean_text.__round__(3))\n",
    "print('Лучшие гиперпараметры:', best_params_Cat_clean_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с подобранными гиперпараметрами на всех обучающих данных и засечём время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения: 18.0 c\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "best_model_Cat_clean_text = CatBoostClassifier(random_state=RANDOM_STATE, eval_metric='F1', task_type='GPU', **best_params_Cat_clean_text)\n",
    "best_model_Cat_clean_text.fit(x_train_DF, y_train, text_features=['text'], silent=True)\n",
    "\n",
    "end = time()\n",
    "\n",
    "time_fit_Cat_clean_text = end - start\n",
    "print('Время обучения:', time_fit_Cat_clean_text.__round__(2), 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 CatBoost + эмбединги от нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "\n",
      "Лучшая метрика F1 на кросс-валидации: 0.918\n",
      "Лучшие гиперпараметры: {'l2_leaf_reg': 10, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "model_Cat_embeddings = CatBoostClassifier(random_state=RANDOM_STATE, eval_metric='F1', task_type='GPU')\n",
    "\n",
    "grid = GridSearchCV(estimator=model_Cat_embeddings, param_grid=params_CatBoost, scoring='f1', cv=2, verbose=0)\n",
    "grid.fit(X=x_train_embedded, y=y_train, silent=True)\n",
    "\n",
    "best_params_Cat_embeddings = grid.best_params_\n",
    "best_metric_Cat_embeddings = grid.best_score_\n",
    "\n",
    "print('-------------------------------------')\n",
    "print()\n",
    "print('Лучшая метрика F1 на кросс-валидации:', best_metric_Cat_embeddings.__round__(3))\n",
    "print('Лучшие гиперпараметры:', best_params_Cat_embeddings) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с подобранными гиперпараметрами на всех обучающих данных и засечём время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения: 15.8 c\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "best_model_Cat_embeddings = CatBoostClassifier(random_state=RANDOM_STATE, eval_metric='F1', task_type='GPU', **best_params_Cat_embeddings)\n",
    "best_model_Cat_embeddings.fit(x_train_embedded, y=y_train, silent=True)\n",
    "\n",
    "end = time()\n",
    "\n",
    "time_fit_Cat_embeddings = end - start\n",
    "print('Время обучения:', time_fit_Cat_embeddings.__round__(2), 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сводные данные по выбору модели\n",
    "1. Наилучшие результаты по метрике показала модель CatBoost с использованием эмбедингов от предобученной нейросети.  \n",
    "- **Остановим выбор на этой конфигурации**   \n",
    "- Однако, стоит отметить, что решение времязатратное и требует использования GPU\n",
    "\n",
    "1. CatBoost c использованием встроенных средств векторизации показала соответсвующую требованиям заказчика точность (0.77 по F1).\n",
    "- такое решение гораздо быстрее выбранного, более того самое быстрое из рассмотренных при использовании GPU.  \n",
    "- Возможно, даже без использования GPU время работы будет достаточно оперативным.\n",
    "\n",
    "1. Логистическая регрессия показывает хорошие результаты (0.77 - 0.88 по F1) при использовании эмбедингов и униграмм по TF-IDF.   \n",
    "Однако использовать решения на основе данной модели не целесообразно, т.к. нет преимуществ по сравнению с бустингом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем общее время на подготовку всех сочетаний модель + предобработка к инференсу. Учтём время на:\n",
    "- лемматизацию\n",
    "- векторизация/получение эмбедингов\n",
    "- обучение модели с подобранными \n",
    "\n",
    "*Очистка данных делается быстро (2-4 c) и используется в любом случае - можно не учитывать.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_tfidf_uni_score = best_metric_LogReg_tfidf_uni.__round__(3)\n",
    "LogReg_tfidf_uni_time = round((time_lemmatization + time_tfidf_uni + time_fit_LogReg_tfidf_uni) / 60, 1)\n",
    "uni_text_vec_time = round((time_lemmatization + time_tfidf_uni) / 60, 1)\n",
    "\n",
    "LogReg_tfidf_di_score = best_metric_LogReg_tfidf_di.__round__(3)\n",
    "LogReg_tfidf_di_time = round((time_lemmatization + time_tfidf_di + time_fit_LogReg_tfidf_di) / 60, 1)\n",
    "di_text_vec_time = round((time_lemmatization + time_tfidf_di) / 60, 1)\n",
    "\n",
    "LogReg_embeddings_score = best_metric_LogReg_embeddings.__round__(3)\n",
    "LogReg_embeddings_time = round((time_fact_embeddings + time_fit_LogReg_embeddings) / 60, 1)\n",
    "\n",
    "embeddings_time = round((time_fact_embeddings) / 60, 1)\n",
    "\n",
    "Cat_clean_text_score = best_metric_Cat_clean_text.__round__(3)\n",
    "Cat_clean_text_time = round((time_fit_Cat_clean_text) / 60, 1)\n",
    "\n",
    "Cat_embeddings_score = best_metric_Cat_embeddings.__round__(3)\n",
    "Cat_embeddings_text_time = round((time_fact_embeddings + time_fit_Cat_embeddings) / 60, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>МЕТРИКА НА КРОСС-ВАЛИДАЦИИ</th>\n",
       "      <th>ОБЩЕЕ ВРЕМЯ ПОДГОТОВКИ К ИНФЕРЕНС, МИН</th>\n",
       "      <th>В Т.Ч. ВРЕМЯ ПРЕОБРАЗОВАНИЯ ТЕКСТОВ, МИН</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CATBOOST ЭМБЕДИНГИ</th>\n",
       "      <td>0.918</td>\n",
       "      <td>49.2</td>\n",
       "      <td>48.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOGISTIC REG ЭМБЕДИНГИ</th>\n",
       "      <td>0.888</td>\n",
       "      <td>50.9</td>\n",
       "      <td>48.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATBOOST ОЧИСТ. ТЕКСТ</th>\n",
       "      <td>0.773</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOGISTIC REG УНИГРАММЫ</th>\n",
       "      <td>0.772</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOGISTIC REG ДИГРАММЫ</th>\n",
       "      <td>0.511</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        МЕТРИКА НА КРОСС-ВАЛИДАЦИИ  \\\n",
       "CATBOOST ЭМБЕДИНГИ                           0.918   \n",
       "LOGISTIC REG ЭМБЕДИНГИ                       0.888   \n",
       "CATBOOST ОЧИСТ. ТЕКСТ                        0.773   \n",
       "LOGISTIC REG УНИГРАММЫ                       0.772   \n",
       "LOGISTIC REG ДИГРАММЫ                        0.511   \n",
       "\n",
       "                        ОБЩЕЕ ВРЕМЯ ПОДГОТОВКИ К ИНФЕРЕНС, МИН  \\\n",
       "CATBOOST ЭМБЕДИНГИ                                        49.2   \n",
       "LOGISTIC REG ЭМБЕДИНГИ                                    50.9   \n",
       "CATBOOST ОЧИСТ. ТЕКСТ                                      0.3   \n",
       "LOGISTIC REG УНИГРАММЫ                                     4.8   \n",
       "LOGISTIC REG ДИГРАММЫ                                     24.6   \n",
       "\n",
       "                        В Т.Ч. ВРЕМЯ ПРЕОБРАЗОВАНИЯ ТЕКСТОВ, МИН  \n",
       "CATBOOST ЭМБЕДИНГИ                                          48.9  \n",
       "LOGISTIC REG ЭМБЕДИНГИ                                      48.9  \n",
       "CATBOOST ОЧИСТ. ТЕКСТ                                        0.0  \n",
       "LOGISTIC REG УНИГРАММЫ                                       0.7  \n",
       "LOGISTIC REG ДИГРАММЫ                                        0.8  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_table = [[LogReg_tfidf_uni_score, LogReg_tfidf_uni_time, uni_text_vec_time],\n",
    "               [LogReg_tfidf_di_score, LogReg_tfidf_di_time, di_text_vec_time],\n",
    "               [LogReg_embeddings_score, LogReg_embeddings_time, embeddings_time],\n",
    "               [Cat_clean_text_score, Cat_clean_text_time, 0],\n",
    "               [Cat_embeddings_score, Cat_embeddings_text_time, embeddings_time]\n",
    "                ]\n",
    "\n",
    "score = pd.DataFrame(index=['LOGISTIC REG УНИГРАММЫ', 'LOGISTIC REG ДИГРАММЫ', 'LOGISTIC REG ЭМБЕДИНГИ', 'CATBOOST ОЧИСТ. ТЕКСТ', 'CATBOOST ЭМБЕДИНГИ'], \n",
    "                     data = score_table, columns=['МЕТРИКА НА КРОСС-ВАЛИДАЦИИ', 'ОБЩЕЕ ВРЕМЯ ПОДГОТОВКИ К ИНФЕРЕНС, МИН', 'В Т.Ч. ВРЕМЯ ПРЕОБРАЗОВАНИЯ ТЕКСТОВ, МИН'])\n",
    "\n",
    "score = score.sort_values(by='МЕТРИКА НА КРОСС-ВАЛИДАЦИИ', ascending=False)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сводные данные по выбору модели\n",
    "\n",
    "1. Наилучшие результаты по метрике показала модель CatBoost с использованием эмбедингов от предобученной нейросети.  \n",
    "- **Остановим выбор на этой конфигурации**   \n",
    "- Однако, стоит отметить, что решение времязатратное и требует использования GPU\n",
    "\n",
    "2. CatBoost c использованием встроенных средств векторизации текста показала точность (0.77 по F1) соответсвующую требованиям заказчика.\n",
    "- такое решение гораздо быстрее выбранного, более того, самое быстрое из рассмотренных при использовании GPU.  \n",
    "- Возможно, даже без использования GPU время работы будет достаточно оперативным.\n",
    "\n",
    "3. Логистическая регрессия показывает хорошие результаты (0.77 - 0.88 по F1) при использовании эмбедингов и униграмм по TF-IDF.   \n",
    "Однако использовать решения на основе данной модели не целесообразно, т.к. нет преимуществ по сравнению с бустингом.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование\n",
    "Проверим модель на адекватность: сравним с бейзлайном - \"дамми\" моделью, предсказывающей исходя из распределения ответов в датасете.  \n",
    "Сделаем \"дамми\" модель на тестовых данных, чтобы имитировать вновь поступающие данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бэйзлан для проверки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика дамми-модели: 0.104\n"
     ]
    }
   ],
   "source": [
    "dummy_model = DummyClassifier (strategy='stratified', random_state=RANDOM_STATE)\n",
    "dummy_model.fit(x_test, y_test)\n",
    "preds = dummy_model.predict(x_test)\n",
    "\n",
    "dummy_test_score = round(f1_score(y_true=y_test, y_pred=preds), 3)\n",
    "\n",
    "print('Метрика дамми-модели:', dummy_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения предсказаний сгенирируем эмбединги для тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 3070 Laptop GPU is available. Running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 777/777 [11:35<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test_embedded = func_get_embedings(x_test, run_on_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая метрика лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговая метрика лучшей модели на тестовых даннных: 0.911\n"
     ]
    }
   ],
   "source": [
    "final_preds = best_model_Cat_embeddings.predict(data=x_test_embedded)\n",
    "final_f1_score = f1_score(y_true=y_test, y_pred=final_preds)\n",
    "\n",
    "print('Итоговая метрика лучшей модели на тестовых даннных:', round(final_f1_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Данную задачу классификации эмоциональной окраски текстов оптимально решать при помощи:**\n",
    "\n",
    "1. Эмбедингов от специализированной предобученной нейросети + модели CatBoost; если доступна работа на GPU:  \n",
    "- Решение позволяет получить очень высокую точность (0.9+ по метрике F1) и превосходит требования заказчика (0.75+)\n",
    "\n",
    "- Ключевым является применение GPU - т.к. без этого ресурса время подготовки к инференс может увеличится в 15-20 раз\n",
    "\n",
    "- Заказчику необходимо подсветить, что даже с использованием GPU подготовка к инференс занимает длительное время.   \n",
    "Это может создать трудности, если требуется часто переобучать модель. \n",
    "\n",
    "2. Модели CatBoost на текстах с минимальной предобработкой (очисткой).  \n",
    "Это хороший вариант при ограниченном времени GPU и необходимости частого переобучения модели.\n",
    "- Такое решение является самым быстрым из рассмотренных\n",
    "\n",
    "- Обеспечивает приемлемый уровень точности (0.77+ по метрике F1), соответсвующий требованиям заказчика\n",
    "\n",
    "- Решение является самым надёжным, т.к.: \n",
    "    - Оно простое, не требует отдельного этапа предобработки\n",
    "    - Не требует использования сторонней предобученной на определённой тематике нейросети\n",
    "\n",
    "3. Использование логистической регрессии и данных предобработанных по технологии TF-IDF не целесообразно.  \n",
    "Данная схема не показала конкурентных результатов ни по времении, ни по точности.   \n",
    "Возможно, у этой схемы есть шанс при работе только на CPU, если подготовка к инференс по варианту 2. будет занимать длительное время.\n",
    "\n",
    "**Возможные пути дальнейшего улучшения решения:**\n",
    "- сделать тонкую предобработку текстов прописав отдельный аглоритм на правилах на основе глубокого анализа текстов\n",
    "- более тонкий подбор гиперпараметров итоговой модели\n",
    "\n",
    "**Необходимо обсудить варианты 1. и 2. с заказчиком и выяснить возможность выделения времени на для работы на GPU**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "184px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
