<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>997375f98854483b88d29d2fda5b1cca</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="анализ-текстов-на-токсичность" class="cell markdown">
<h1>Анализ текстов на токсичность</h1>
<p>Интернет-магазин запускает новый сервис: пользователи могут
редактировать и дополнять описания товаров, как в
вики-сообществах.<br />
Магазину нужен инструмент, который будет искать токсичные комментарии и
отправлять их на модерацию.</p>
<p><strong>Задача</strong></p>
<ul>
<li>Создать модель для классификации комментариев на позитивные и
негативные<br />
</li>
<li>Модель должна обеспечивать значение метрики качества <em>F1</em> не
меньше 0.75<br />
</li>
<li>Имеет значение ресурсоёмкость решения:
<ul>
<li>сколько требуется времени для подготовки модели к инфренсу?</li>
<li>требуются ли ресурсы GPU для решения задачи?</li>
</ul></li>
</ul>
<p><strong>Способ решения</strong></p>
<p>Исследовать несколько сочетаний моделей и способов предобработки
текста и предложить в продакшн оптимальный вариант.<br />
С заказчиком согласовано исследование следующих моделей:</p>
<ul>
<li>Логистическая регрессия</li>
<li>Бустинг CatBoost</li>
</ul>
<p>А также кодирование текста при помощи:</p>
<ul>
<li>Методики TF-IDF</li>
<li>Предобученной нейросети</li>
</ul>
</section>
<section id="описание-данных" class="cell markdown">
<h2>Описание данных</h2>
<p>Имеется набор размеченных данных по токсичности правок.</p>
<p>Данные находятся в файле <code>toxic_comments.csv</code>.<br />
Столбец <em>text</em> в нём содержит текст комментария, а <em>toxic</em>
— бинарный целевой признак (1/0).</p>
</section>
<section id="план-работы" class="cell markdown">
<h2>План работы</h2>
<ol>
<li>Загрузить и исследовать данные:
<ul>
<li>Изучить данные, проверить их на предмет пропусков, аномалий и
дубликатов</li>
<li>Исследовать данные на дисбаланс классов</li>
</ul></li>
<li>Предобработать данные, подготовить отдельные датасеты для
моделирования:
<ul>
<li>Очистить данные от спец. символов, цифр, знаков препинания и
др.</li>
<li>Повторно проверить на аномалии</li>
<li>Разбить данные на обучающую и тестовую(20%) выборки</li>
<li>Сделать векторизацию тестов по TF-IDF:
<ul>
<li>лемматизировать текстовые данные</li>
<li>удалить стоп-слова и сгенерировать дополнительные признаки с
использованием:
<ul>
<li>униграмм</li>
<li>диграмм</li>
</ul></li>
</ul></li>
<li>Подобрать подходящую под задачу предобученную нейросеть из
сообщества Hugging Face и сгенерировать эмбединги текстов</li>
</ul></li>
<li>Исследовать модели с использованием обозначенных выше способов
предобработки:
<ul>
<li>Обучить модели с подбором гиперпараметров на кросс-валидации:
<ul>
<li>Логистическая регрессия:
<ul>
<li>TF-IDF на униграммах</li>
<li>TF-IDF на диграммах</li>
<li>эмбединги от нейросети<br />
</li>
</ul></li>
<li>Бустинг CatBoost:
<ul>
<li>очищенный текст без векторизации <em>(i)</em></li>
<li>эмбединги от нейросети</li>
</ul></li>
</ul></li>
<li>Сделать сводую таблицу результатов и выбрать оптимальную модель и
тип предобработки</li>
</ul></li>
<li>Тестирование
<ul>
<li>Сгенерировать "дамми" модель для проверки оптимальной модели на
адекватность</li>
<li>Проверить оптимальную модель и способ предобработки на тестовых
данных</li>
</ul></li>
<li>Составить выводы и рекомендации</li>
</ol>
<p><em>(i) Модель Catboost имеет встроенные средства векторизации
текстов - можно подавать текстовые признаки без кодирования.</em></p>
</section>
<section id="подготовка-и-первичный-анализ" class="cell markdown">
<h2>Подготовка и первичный анализ</h2>
</section>
<section id="загрузка-библиотек" class="cell markdown">
<h3>Загрузка библиотек</h3>
</section>
<div class="cell code" data-execution_count="45">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Прогресс выполнения и время работы</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>tqdm.pandas()</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> time</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Работа с текстом</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">#Нейросети</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> BertTokenizer, BertModel</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">#Борьба с регулярными выражениями</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Лемматизация</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> SnowballStemmer</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Стоп-слова для исключения и леммация англ</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>stopwords <span class="op">=</span> stopwords.words(<span class="st">&#39;english&#39;</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Класс для генерации признаков как матрицы TF-IDF для слов</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Модели </span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.dummy <span class="im">import</span> DummyClassifier</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> catboost <span class="im">import</span> CatBoostClassifier</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Метрики, разделялки и впомогательные для моделей</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV, RandomizedSearchCV</span></code></pre></div>
</div>
<section id="настройки-и-константы" class="cell markdown">
<h3>Настройки и константы</h3>
</section>
<div class="cell code" data-execution_count="46">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>RANDOM_STATE <span class="op">=</span> <span class="dv">12345</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(RANDOM_STATE)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    torch.cuda.manual_seed_all(RANDOM_STATE)</span></code></pre></div>
</div>
<section id="пользовательские-функции" class="cell markdown">
<h3>Пользовательские функции</h3>
</section>
<div class="cell markdown">
<p>Очистка текста</p>
<ul>
<li>Удаляет все спец. символы, знаки препинания и лишние пробелы</li>
<li>Приводит данные к единому регистру</li>
</ul>
</div>
<div class="cell code" data-execution_count="47">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> func_clear_text_lower(text):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> re.sub(<span class="vs">r&#39;[^a-zA-Z]&#39;</span>, <span class="st">&#39; &#39;</span>, text)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> <span class="st">&quot; &quot;</span>.join(t.split())</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> t.lower()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> t</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Лемматизация</p>
<ul>
<li>Использует быстрый лемматизатор Snowball для английского языка</li>
</ul>
<p><em>Пробовал лемматизатор из Spacy, работает на порядки медленнее, а
результат по метрике +/- тот же.</em></p>
</div>
<div class="cell code" data-execution_count="48">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> func_lemmatize_engl(text):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    stemmer <span class="op">=</span> SnowballStemmer(language<span class="op">=</span><span class="st">&#39;english&#39;</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> <span class="bu">list</span>(text.split())</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> []</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> a <span class="kw">in</span> t:</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        result.append(stemmer.stem(a))</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> <span class="st">&#39; &#39;</span>.join(result)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Генерация эмбедингов с помощью предобученной нейросети</p>
<ul>
<li>Можно задать имя нейросети из комьюнити Hugging Face</li>
<li>По умолчанию - BERT для токсичных комментариев, т.к. эта нейросеть
как раз под задачу данного проекта</li>
<li>Работает на CPU или GPU. По умолчанию GPU.</li>
</ul>
</div>
<div class="cell code" data-execution_count="49">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> func_get_embedings(series_to_encode, run_on_gpu<span class="op">=</span><span class="va">True</span>, hugface_model_name:<span class="bu">str</span><span class="op">=</span><span class="st">&#39;unitary/toxic-bert&#39;</span>, batch_limit<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Сохранение исходного индекса df/series</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    series_to_encode_index <span class="op">=</span> series_to_encode.index</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Загрузка модели и её токенизатора</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    tokenizer <span class="op">=</span> BertTokenizer.from_pretrained(hugface_model_name)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> BertModel.from_pretrained(hugface_model_name)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Токенизация и кодирование</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    tokenized_texts <span class="op">=</span> tokenizer.batch_encode_plus(</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>                                series_to_encode,</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>                                padding<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>                                truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>                                return_tensors<span class="op">=</span><span class="st">&#39;pt&#39;</span>,</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>                                add_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    input_ids <span class="op">=</span> tokenized_texts[<span class="st">&#39;input_ids&#39;</span>]</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    attention_mask <span class="op">=</span> tokenized_texts[<span class="st">&#39;attention_mask&#39;</span>]</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Найдём максимальный размера батча (делитель без остатка) в заданном лимите </span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(series_to_encode) <span class="op">%</span> batch_limit <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        batch_limit <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> batch_limit</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    embeddings <span class="op">=</span> []</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Если работаем на GPU, то предварительно переводим модель и все тензоры на GPU</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Предварительно проверим, доступна ли работа на GPU</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> run_on_gpu:</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;GPU: </span><span class="sc">{</span>torch<span class="sc">.</span>cuda<span class="sc">.</span>get_device_name(<span class="dv">0</span>)<span class="sc">}</span><span class="ss"> is available. Running on GPU&quot;</span>)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> tqdm(<span class="bu">range</span>(input_ids.shape[<span class="dv">0</span>] <span class="op">//</span> batch_size)):</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>                model <span class="op">=</span> model.to(<span class="st">&#39;cuda&#39;</span>)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>                batch <span class="op">=</span> torch.LongTensor(input_ids[batch_size<span class="op">*</span>i:batch_size<span class="op">*</span>(i<span class="op">+</span><span class="dv">1</span>)]).to(<span class="st">&#39;cuda&#39;</span>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>                attention_mask_batch <span class="op">=</span> torch.LongTensor(attention_mask[batch_size<span class="op">*</span>i:batch_size<span class="op">*</span>(i<span class="op">+</span><span class="dv">1</span>)]).to(<span class="st">&#39;cuda&#39;</span>)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Генерация эмбедингов</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>                <span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>                    outputs <span class="op">=</span> model(batch, attention_mask<span class="op">=</span>attention_mask_batch)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>                    embeddings_batch <span class="op">=</span> outputs.last_hidden_state.mean(dim<span class="op">=</span><span class="dv">1</span>).cpu().numpy()</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>                    embeddings.append(embeddings_batch)</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        torch.cuda.empty_cache() <span class="co"># Обязательно очистить кэш GPU, иначе возможны сбои kernel           </span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Training will run on CPU.&quot;</span>)</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> tqdm(<span class="bu">range</span>(input_ids.shape[<span class="dv">0</span>] <span class="op">//</span> batch_size)):</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>            batch <span class="op">=</span> torch.LongTensor(input_ids[batch_size<span class="op">*</span>i:batch_size<span class="op">*</span>(i<span class="op">+</span><span class="dv">1</span>)])</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>            attention_mask_batch <span class="op">=</span> torch.LongTensor(attention_mask[batch_size<span class="op">*</span>i:batch_size<span class="op">*</span>(i<span class="op">+</span><span class="dv">1</span>)])</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Генерация эмбедингов</span></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> model(batch, attention_mask<span class="op">=</span>attention_mask_batch)</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>                embeddings_batch <span class="op">=</span> outputs.last_hidden_state.mean(dim<span class="op">=</span><span class="dv">1</span>).numpy()</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>                embeddings.append(embeddings_batch)</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(np.concatenate(embeddings), index<span class="op">=</span>series_to_encode_index)</span></code></pre></div>
</div>
<section id="загрузка-и-знакомство-с-данными" class="cell markdown">
<h3>Загрузка и знакомство с данными</h3>
</section>
<div class="cell code" data-execution_count="50">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.read_csv(<span class="st">&#39;toxic_comments.csv&#39;</span>, index_col<span class="op">=</span><span class="st">&#39;Unnamed: 0&#39;</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span>:</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.read_csv(<span class="st">&#39;/datasets/toxic_comments.csv&#39;</span>, index_col<span class="op">=</span><span class="st">&#39;Unnamed: 0&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="51">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>df.info()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Index: 159292 entries, 0 to 159450
Data columns (total 2 columns):
 #   Column  Non-Null Count   Dtype 
---  ------  --------------   ----- 
 0   text    159292 non-null  object
 1   toxic   159292 non-null  int64 
dtypes: int64(1), object(1)
memory usage: 3.6+ MB
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="52">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>df.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="52">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>toxic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Explanation\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>"\nMore\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of ""types of accidents""  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\n\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  "</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="53">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Количество дубликатов:&#39;</span>, df[<span class="st">&#39;text&#39;</span>].duplicated().<span class="bu">sum</span>())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Количество дубликатов: 0
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="54">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Количество пустых текстовых записей:&#39;</span>, df.loc[(df[<span class="st">&#39;text&#39;</span>]<span class="op">==</span><span class="st">&#39;&#39;</span>)<span class="op">|</span>(df[<span class="st">&#39;text&#39;</span>]<span class="op">==</span><span class="st">&#39; &#39;</span>)][<span class="st">&#39;text&#39;</span>].count())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Количество пустых текстовых записей: 0
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="55">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Средняя длинна текста:&#39;</span>, <span class="bu">round</span>(df[<span class="st">&#39;text&#39;</span>].<span class="bu">str</span>.<span class="bu">len</span>().mean()))</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Максимальная длинна текста:&#39;</span>, <span class="bu">len</span>(df[<span class="st">&#39;text&#39;</span>].<span class="bu">max</span>()))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Средняя длинна текста: 394
Максимальная длинна текста: 4521
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Исследование баланса классов</p>
</div>
<div class="cell code" data-execution_count="56">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>class_balance <span class="op">=</span> df[<span class="st">&#39;toxic&#39;</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>).<span class="bu">round</span>(<span class="dv">3</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Доля нетоксичных записей&#39;</span>, class_balance[<span class="dv">0</span>]<span class="op">*</span><span class="dv">100</span>, <span class="st">&#39;%&#39;</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Доля токсичных записей&#39;</span>, class_balance[<span class="dv">1</span>]<span class="op">*</span><span class="dv">100</span>, <span class="st">&#39;%&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Доля нетоксичных записей 89.8 %
Доля токсичных записей 10.2 %
</code></pre>
</div>
</div>
<div class="cell markdown">
<p><strong>Выводы первичного анализа данных</strong></p>
<ul>
<li>Данных (159 тыс. строк) достаточно для тестирования выбранных типов
моделей и кодирования</li>
<li>Пропусков и дубликатов нет</li>
<li>Текстовый массив затруднительно обработать простыми аголоритмами,
т.к. макс. длинна текста 4500, а средняя длинна 394 символа</li>
<li>Сильный дисбаланс классов (9 к 1). Потребуется учитывать это при
использовании Логистической регрессии</li>
<li>Текстовые данные "грязные", есть спец символы (\n и др.), разный
регистр и т.д.</li>
<li>Текст не лемматизирован</li>
</ul>
</div>
<section id="предобработка-данных" class="cell markdown">
<h2>Предобработка данных</h2>
</section>
<section id="очистка-данных" class="cell markdown">
<h3>Очистка данных</h3>
</section>
<div class="cell code" data-execution_count="57">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;text&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;text&#39;</span>].<span class="bu">apply</span>(func_clear_text_lower)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Проверим не образовались ли пустые записи и/или состоящие из пробела
после очистки текста.<br />
Такое может быть, если текст состоял только из пробелов и/или спец.
символов.</p>
<p>Если таких наблюдений немного, то можно их отбросить.</p>
</div>
<div class="cell code" data-execution_count="58">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;text&#39;</span>].isna().<span class="bu">sum</span>()</span></code></pre></div>
<div class="output execute_result" data-execution_count="58">
<pre><code>0</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="59">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Количество пустых текстовых записей:&#39;</span>, df.loc[(df[<span class="st">&#39;text&#39;</span>]<span class="op">==</span><span class="st">&#39;&#39;</span>)<span class="op">|</span>(df[<span class="st">&#39;text&#39;</span>]<span class="op">==</span><span class="st">&#39; &#39;</span>)][<span class="st">&#39;text&#39;</span>].count())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Количество пустых текстовых записей: 11
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="60">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.loc[(df[<span class="st">&#39;text&#39;</span>]<span class="op">!=</span><span class="st">&#39;&#39;</span>)<span class="op">&amp;</span>(df[<span class="st">&#39;text&#39;</span>]<span class="op">!=</span><span class="st">&#39; &#39;</span>)]</span></code></pre></div>
</div>
<section id="разбиение-данных-на-обучающую-и-тестовую-20-выборки"
class="cell markdown">
<h3>Разбиение данных на обучающую и тестовую (20%) выборки</h3>
<ul>
<li>Т.к. предобработка будет отличаться в зависимости от типа модели,
заранее разобьём данные</li>
<li>Тестовые данные предобработаем под потребности итоговой модели,
которую будем на них проверять</li>
<li>Дисбаланс классов при разбиении не учитываем - <strong>нет
гарантии</strong>, что на вновь поступающих данных он будет таким
же</li>
</ul>
</section>
<div class="cell code" data-execution_count="61">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>df_train, df_test <span class="op">=</span> train_test_split(df, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span>RANDOM_STATE)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="62">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> df_train[<span class="st">&#39;text&#39;</span>]</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> df_train[<span class="st">&#39;toxic&#39;</span>]</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> df_test[<span class="st">&#39;text&#39;</span>]</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> df_test[<span class="st">&#39;toxic&#39;</span>]</span></code></pre></div>
</div>
<section id="векторизация-по-tf-idf" class="cell markdown">
<h3>Векторизация по TF-IDF</h3>
<p>Лемматизируем текст и подготовим датасеты с генерацией признаков по
TF-IDF:</p>
<ul>
<li>с униграммами</li>
<li>с диграммами</li>
</ul>
<p>Запишем время, необходимое для этих операций, чтобы потом учесть его
в общей скорости обучения соотв. моделей.</p>
</section>
<div class="cell markdown">
<p>Лемматизация</p>
</div>
<div class="cell code" data-execution_count="63">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>x_train_lemmatized <span class="op">=</span> x_train.copy()</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>x_train_lemmatized <span class="op">=</span> x_train_lemmatized.<span class="bu">apply</span>(func_lemmatize_engl)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time()</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>time_lemmatization <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Время лемматизации:&#39;</span>, time_lemmatization.__round__(<span class="dv">1</span>), <span class="st">&#39;c&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Время лемматизации: 34.3 c
</code></pre>
</div>
</div>
<section id="tf-idf-с-униграммами" class="cell markdown">
<h4>TF-IDF с униграммами</h4>
</section>
<div class="cell code" data-execution_count="64">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>vectorizer_uni <span class="op">=</span> TfidfVectorizer(stop_words<span class="op">=</span>stopwords) </span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>vectorizer_uni.fit(x_train_lemmatized)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>x_train_tfidf_uni <span class="op">=</span> vectorizer_uni.transform(x_train_lemmatized)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time()</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>time_tfidf_uni <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Количество полученных признаков:&quot;</span>, x_train_tfidf_uni.shape[<span class="dv">1</span>])</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Время генерации:&quot;</span>, time_tfidf_uni.__round__(<span class="dv">1</span>), <span class="st">&#39;c&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Количество полученных признаков: 115213
Время генерации: 6.4 c
</code></pre>
</div>
</div>
<section id="tf-idf-с-диграммами" class="cell markdown">
<h4>TF-IDF с диграммами</h4>
</section>
<div class="cell code" data-execution_count="65">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>vectorizer_di <span class="op">=</span> TfidfVectorizer(stop_words<span class="op">=</span>stopwords, ngram_range<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">2</span>)) </span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>vectorizer_di.fit(x_train_lemmatized)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>x_train_tfidf_di <span class="op">=</span> vectorizer_di.transform(x_train_lemmatized)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time()</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>time_tfidf_di <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Количество полученных признаков:&quot;</span>, x_train_tfidf_di.shape[<span class="dv">1</span>])</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Время генерации:&quot;</span>, time_tfidf_di.__round__(<span class="dv">1</span>), <span class="st">&#39;с&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Количество полученных признаков: 1867778
Время генерации: 14.1 с
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Вот оно как. Наблюдаем взрыв признаков при переходе на
диграммы.<br />
Число признаков увеличилось в 16 раз до 1,8+ млн.<br />
Для дальнейшей работы моделей это не лучший вариант из-за слишком
долгого времени работы, особенно с подбором гиперпараметров.</p>
<p>Ограничим число признаков при генерации 1 млн. Векторизатор отберёт
их по частоте встречаемости в корпусе.</p>
</div>
<div class="cell code" data-execution_count="66">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>vectorizer_di <span class="op">=</span> TfidfVectorizer(stop_words<span class="op">=</span>stopwords, ngram_range<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">2</span>), max_features<span class="op">=</span><span class="dv">1000000</span>) </span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>vectorizer_di.fit(x_train_lemmatized)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>x_train_tfidf_di <span class="op">=</span> vectorizer_di.transform(x_train_lemmatized)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time()</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>time_tfidf_di <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Количество полученных признаков:&quot;</span>, x_train_tfidf_di.shape[<span class="dv">1</span>])</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Время генерации:&quot;</span>, time_tfidf_di.__round__(<span class="dv">1</span>), <span class="st">&#39;с&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Количество полученных признаков: 1000000
Время генерации: 14.6 с
</code></pre>
</div>
</div>
<section id="получение-эмбедингов-с-помощью-нейросети-bert"
class="cell markdown">
<h3>Получение эмбедингов с помощью нейросети BERT</h3>
<p>Используем данные, очищенные от спец символов, цифр, знаков
препинания.<br />
Не делаем лематизацию и удаление стоп-слов, т.к. это может помешать
нейросети оценить контекст.</p>
<p>Используем предобученную нейросеть специализующуюся на токсичных
комментариях.</p>
<p>Данных много. Прежде, чем перейти к расчёту эмбедингов, оценим
примерное время для выполнения задачи на CPU и GPU.<br />
<strong>Время GPU существенно дороже, если время выполнения позволяет,
то лучше обойтись CPU</strong></p>
<p>Сделаем эмбединги для 500 текстовых записей и расчитаем время на
обработку всего корпуса.</p>
</section>
<section id="оценка-времени-выполнения-задачи-на-cpu-и-gpu"
class="cell markdown">
<h4>Оценка времени выполнения задачи на CPU и GPU</h4>
</section>
<div class="cell markdown">
<p>CPU</p>
</div>
<div class="cell code" data-execution_count="67">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>embedings_trial <span class="op">=</span> func_get_embedings(x_train[<span class="dv">0</span>:<span class="dv">500</span>], run_on_gpu<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time()</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>time_estimation_embeddings_cpu <span class="op">=</span> <span class="bu">round</span>((end <span class="op">-</span> start) <span class="op">*</span> (<span class="bu">len</span>(x_train) <span class="op">/</span> <span class="dv">1000</span>) <span class="op">/</span> <span class="dv">60</span>, <span class="dv">0</span>)   </span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span> embedings_trial</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Расчётное время для получения эмбедингов на CPU:&quot;</span>, time_estimation_embeddings_cpu, <span class="st">&#39;минут&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Training will run on CPU.
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 5/5 [04:10&lt;00:00, 50.11s/it]</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Расчётное время для получения эмбедингов на CPU: 535.0 минут
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>GPU</p>
</div>
<div class="cell code" data-execution_count="68">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>embedings_trial <span class="op">=</span> func_get_embedings(x_train[<span class="dv">0</span>:<span class="dv">500</span>], run_on_gpu<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time()</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>time_estimation_embeddings_gpu <span class="op">=</span> <span class="bu">round</span>((end <span class="op">-</span> start) <span class="op">*</span> (<span class="bu">len</span>(x_train) <span class="op">/</span> <span class="dv">1000</span>) <span class="op">/</span> <span class="dv">60</span>, <span class="dv">0</span>)   </span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span> embedings_trial</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Расчётное время для получения эмбедингов на видеокарте (GPU):&quot;</span>, time_estimation_embeddings_gpu, <span class="st">&#39;минут&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>GPU: NVIDIA GeForce RTX 3070 Laptop GPU is available. Running on GPU
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 5/5 [00:10&lt;00:00,  2.11s/it]</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Расчётное время для получения эмбедингов на видеокарте (GPU): 26.0 минут
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>
</code></pre>
</div>
</div>
<div class="cell markdown">
<p><strong>Вывод:</strong></p>
<ul>
<li>Будем работать на GPU, т.к. расчётно потребуется всего ок. 30
мин<br />
</li>
<li>Время получения эмбедингов на CPU слишком долгое - в 20 раз больше
чем на GPU (590+ мин или ок. 10 часов)</li>
</ul>
</div>
<section id="получение-эмбедингов-для-обучающей-выборки"
class="cell markdown">
<h4>Получение эмбедингов для обучающей выборки</h4>
<p><em>Если эмбединги ранее уже были получены на этапе разработки, то
загрузим из файла.</em></p>
</section>
<div class="cell code" data-execution_count="69">
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    x_train_embedded <span class="op">=</span> pd.read_pickle(<span class="st">&#39;x_train_embedded.pkl&#39;</span>)    </span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    time_fact_embeddings <span class="op">=</span> <span class="fl">2936.13</span> <span class="co"># Замерено ранее</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span>:    </span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time()</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    x_train_embedded <span class="op">=</span> func_get_embedings(x_train, run_on_gpu<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>    x_train_embedded.to_pickle(<span class="st">&#39;x_train_embedded.pkl&#39;</span>)</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>    end <span class="op">=</span> time()</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>    time_fact_embeddings <span class="op">=</span> end <span class="op">-</span> start</span></code></pre></div>
</div>
<section id="моделирование" class="cell markdown">
<h2>Моделирование</h2>
<p>Проверим различные сочетания моделей и предобработки данных на
кросс-валидации с подбором гиперпараметров.<br />
Подбор гиперпараметров может существенно повлиять на точность
Логистической регрессии.</p>
</section>
<section id="1-логистическая-регрессия" class="cell markdown">
<h3>1 Логистическая регрессия</h3>
</section>
<div class="cell markdown">
<p>Зададим единую сетку для подбора гиперпараметров всех подвидов
модели.</p>
<ul>
<li>В данных сильный дисбаланс классов: учтём это и поставим настройку
'classifier__class_weight' = 'balanced'</li>
<li>Используем алгоритм 'saga', он лучше подходят для больших датасетов
+ поддерживает смешанную регуляризацию ElasticNet</li>
<li>Для повышения точности модели важно оптимизировать параметры
регуляризации весов:
<ul>
<li>Для этого используем смешанную регуляризацию Elasticnet + подбор
коэф. l1/l2</li>
<li>Инверсию регуляризации (параметр 'C')</li>
</ul></li>
</ul>
<p>Датасет достаточно большой, а также хочется проверить широкий круг
гиперпараметров.<br />
Чтобы сэкономить время проведём подбор гиперпараметров в 2 этапа:</p>
<ul>
<li>Сузим круг поиска за счёт предварительного случайного поиска по
сетке параметров с заданным числом итераций</li>
<li>Проведём поиск по более узкой сетке для каждой модели</li>
</ul>
</div>
<section
id="0-случайный-подбор-гиперпараметров-логистической-регрессии-для-сужения-сетки-поиска"
class="cell markdown">
<h4>0 Случайный подбор гиперпараметров Логистической регрессии для
сужения сетки поиска</h4>
</section>
<div class="cell markdown">
<p>Исходная широкая сетка гиперпараметров</p>
</div>
<div class="cell code" data-execution_count="70">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>params_LogReg_long <span class="op">=</span> [{<span class="st">&#39;solver&#39;</span>: [<span class="st">&#39;saga&#39;</span>],                <span class="co"># default &#39;lbfgs&#39;</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&#39;class_weight&#39;</span>: [<span class="st">&#39;balanced&#39;</span>],      <span class="co"># default None</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&#39;penalty&#39;</span>:[<span class="st">&#39;elasticnet&#39;</span>],          <span class="co"># default l2</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&#39;l1_ratio&#39;</span>:[<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="fl">0.3</span>, <span class="fl">0.7</span>, <span class="dv">1</span>],  <span class="co"># default None</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&#39;max_iter&#39;</span>: [<span class="dv">100</span>, <span class="dv">150</span>],            <span class="co"># default 100</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&#39;C&#39;</span>: <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>)                  <span class="co"># default 1.0</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>                      }]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="71">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>model_LogReg_try <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> RandomizedSearchCV(estimator<span class="op">=</span>model_LogReg_try, param_distributions<span class="op">=</span>params_LogReg_long, </span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>                          scoring<span class="op">=</span><span class="st">&#39;f1&#39;</span>, cv<span class="op">=</span><span class="dv">2</span>, n_iter<span class="op">=</span><span class="dv">25</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">0</span>) </span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>grid.fit(X<span class="op">=</span>x_train_tfidf_uni, y<span class="op">=</span>y_train)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>best_params_LogReg_try <span class="op">=</span> grid.best_params_</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>best_metric_LogReg_try <span class="op">=</span> grid.best_score_</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;--------------------------------------------------------------------------&#39;</span>)</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Лучшая метрика F1 на кросс-валидации:&#39;</span>, best_metric_LogReg_try.__round__(<span class="dv">3</span>))</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Лучшие гиперпараметры:&#39;</span>, best_params_LogReg_try)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>--------------------------------------------------------------------------
Лучшая метрика F1 на кросс-валидации: 0.767
Лучшие гиперпараметры: {&#39;solver&#39;: &#39;saga&#39;, &#39;penalty&#39;: &#39;elasticnet&#39;, &#39;max_iter&#39;: 150, &#39;l1_ratio&#39;: 1, &#39;class_weight&#39;: &#39;balanced&#39;, &#39;C&#39;: 3}
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>e:\UpdatedProject Venv on Python 3.12.2\.venv\Lib\site-packages\sklearn\linear_model\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Итоговая сокращенная сетка для поиска гиперпараметров</p>
</div>
<div class="cell code" data-execution_count="72">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>params_LogReg <span class="op">=</span> [{<span class="st">&#39;solver&#39;</span>: [<span class="st">&#39;saga&#39;</span>],           <span class="co"># default &#39;lbfgs&#39;</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&#39;class_weight&#39;</span>: [<span class="st">&#39;balanced&#39;</span>], <span class="co"># default None</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&#39;penalty&#39;</span>:[<span class="st">&#39;elasticnet&#39;</span>],     <span class="co"># default l2</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&#39;l1_ratio&#39;</span>:[<span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span>],   <span class="co"># default None</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&#39;max_iter&#39;</span>: [<span class="dv">150</span>],            <span class="co"># default 100</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&#39;C&#39;</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">9</span>]                <span class="co"># default 1.0</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>                }]</span></code></pre></div>
</div>
<section
id="11-логистическая-регрессия--векторизация-по-tf-idf-с-униграммами"
class="cell markdown">
<h4>1.1 Логистическая регрессия + векторизация по TF-IDF с
униграммами</h4>
</section>
<div class="cell code" data-execution_count="73">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>model_LogReg_tfidf_uni <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>model_LogReg_tfidf_uni, param_grid<span class="op">=</span>params_LogReg, scoring<span class="op">=</span><span class="st">&#39;f1&#39;</span>, cv<span class="op">=</span><span class="dv">2</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">0</span>) </span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>grid.fit(X<span class="op">=</span>x_train_tfidf_uni, y<span class="op">=</span>y_train)</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>best_params_LogReg_tfidf_uni <span class="op">=</span> grid.best_params_</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>best_metric_LogReg_tfidf_uni <span class="op">=</span> grid.best_score_</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Лучшая метрика F1 на кросс-валидации:&#39;</span>, best_metric_LogReg_tfidf_uni.__round__(<span class="dv">3</span>))</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Лучшие гиперпараметры:&#39;</span>, best_params_LogReg_tfidf_uni) </span></code></pre></div>
<div class="output stream stdout">
<pre><code>Лучшая метрика F1 на кросс-валидации: 0.772
Лучшие гиперпараметры: {&#39;C&#39;: 2, &#39;class_weight&#39;: &#39;balanced&#39;, &#39;l1_ratio&#39;: 0.7, &#39;max_iter&#39;: 150, &#39;penalty&#39;: &#39;elasticnet&#39;, &#39;solver&#39;: &#39;saga&#39;}
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>e:\UpdatedProject Venv on Python 3.12.2\.venv\Lib\site-packages\sklearn\linear_model\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Обучим модель с подобранными гиперпараметрами на всех обучающих
данных и засечём время.</p>
</div>
<div class="cell code" data-execution_count="74">
<div class="sourceCode" id="cb53"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>best_model_LogReg_tfidf_uni <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span>RANDOM_STATE, <span class="op">**</span>best_params_LogReg_tfidf_uni)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>best_model_LogReg_tfidf_uni.fit(x_train_tfidf_uni, y_train)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time()</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>time_fit_LogReg_tfidf_uni <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Время обучения:&#39;</span>, time_fit_LogReg_tfidf_uni.__round__(<span class="dv">3</span>), <span class="st">&#39;c&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Время обучения: 245.536 c
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>e:\UpdatedProject Venv on Python 3.12.2\.venv\Lib\site-packages\sklearn\linear_model\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
</code></pre>
</div>
</div>
<section
id="12-логистическая-регрессия--векторизация-по-tf-idf-с-диграммами"
class="cell markdown">
<h4>1.2 Логистическая регрессия + векторизация по TF-IDF с
диграммами</h4>
</section>
<div class="cell code" data-execution_count="75">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>model_LogReg_tfidf_di <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>model_LogReg_tfidf_di, param_grid<span class="op">=</span>params_LogReg, scoring<span class="op">=</span><span class="st">&#39;f1&#39;</span>, cv<span class="op">=</span><span class="dv">2</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">0</span>) </span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>grid.fit(X<span class="op">=</span>x_train_tfidf_di, y<span class="op">=</span>y_train)</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>best_params_LogReg_tfidf_di <span class="op">=</span> grid.best_params_</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>best_metric_LogReg_tfidf_di <span class="op">=</span> grid.best_score_</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Лучшая метрика F1 на кросс-валидации:&#39;</span>, best_metric_LogReg_tfidf_di.__round__(<span class="dv">3</span>))</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Лучшие гиперпараметры:&#39;</span>, best_params_LogReg_tfidf_di)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Лучшая метрика F1 на кросс-валидации: 0.511
Лучшие гиперпараметры: {&#39;C&#39;: 9, &#39;class_weight&#39;: &#39;balanced&#39;, &#39;l1_ratio&#39;: 0.9, &#39;max_iter&#39;: 150, &#39;penalty&#39;: &#39;elasticnet&#39;, &#39;solver&#39;: &#39;saga&#39;}
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>e:\UpdatedProject Venv on Python 3.12.2\.venv\Lib\site-packages\sklearn\linear_model\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Обучим модель с подобранными гиперпараметрами на всех обучающих
данных и засечём время.</p>
</div>
<div class="cell code" data-execution_count="76">
<div class="sourceCode" id="cb59"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>best_model_LogReg_tfidf_di <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span>RANDOM_STATE, <span class="op">**</span>best_params_LogReg_tfidf_di)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>best_model_LogReg_tfidf_di.fit(x_train_tfidf_di, y_train)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time()</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>time_fit_LogReg_tfidf_di <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Время обучения:&#39;</span>, time_fit_LogReg_tfidf_di.__round__(<span class="dv">2</span>), <span class="st">&#39;c&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Время обучения: 1424.63 c
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>e:\UpdatedProject Venv on Python 3.12.2\.venv\Lib\site-packages\sklearn\linear_model\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
</code></pre>
</div>
</div>
<section id="13-логистическая-регрессия--эмбединги-от-нейросети"
class="cell markdown">
<h4>1.3 Логистическая регрессия + эмбединги от нейросети</h4>
</section>
<div class="cell code" data-execution_count="77">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>model_LogReg_embeddings <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>model_LogReg_embeddings, param_grid<span class="op">=</span>params_LogReg, scoring<span class="op">=</span><span class="st">&#39;f1&#39;</span>, cv<span class="op">=</span><span class="dv">2</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">0</span>) </span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>grid.fit(X<span class="op">=</span>x_train_embedded, y<span class="op">=</span>y_train) </span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>best_params_LogReg_embeddings <span class="op">=</span> grid.best_params_</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>best_metric_LogReg_embeddings <span class="op">=</span> grid.best_score_</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Лучшая метрика F1 на кросс-валидации:&#39;</span>, best_metric_LogReg_embeddings.__round__(<span class="dv">2</span>))</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Лучшие гиперпараметры:&#39;</span>, best_params_LogReg_embeddings)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Лучшая метрика F1 на кросс-валидации: 0.89
Лучшие гиперпараметры: {&#39;C&#39;: 5, &#39;class_weight&#39;: &#39;balanced&#39;, &#39;l1_ratio&#39;: 0.8, &#39;max_iter&#39;: 150, &#39;penalty&#39;: &#39;elasticnet&#39;, &#39;solver&#39;: &#39;saga&#39;}
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>e:\UpdatedProject Venv on Python 3.12.2\.venv\Lib\site-packages\sklearn\linear_model\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Обучим модель с подобранными гиперпараметрами на всех обучающих
данных и засечём время.</p>
</div>
<div class="cell code" data-execution_count="78">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>best_model_LogReg_embeddings <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span>RANDOM_STATE, <span class="op">**</span>best_params_LogReg_embeddings)</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>best_model_LogReg_embeddings.fit(x_train_embedded, y_train)</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time()</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>time_fit_LogReg_embeddings <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Время обучения:&#39;</span>, time_fit_LogReg_embeddings.__round__(<span class="dv">2</span>), <span class="st">&#39;c&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Время обучения: 116.08 c
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>e:\UpdatedProject Venv on Python 3.12.2\.venv\Lib\site-packages\sklearn\linear_model\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(
</code></pre>
</div>
</div>
<section id="2-бустинг-catboost" class="cell markdown">
<h3>2. Бустинг CatBoost</h3>
</section>
<div class="cell markdown">
<p>В CatBoost встроены токенизатор и методы векторизации, поэтому мало
смысла использовать отдельную векторизацию по TF-IDF.<br />
Попробуем подать на вход два варианта предобработки:</p>
<ul>
<li>только с базовой очисткой текста</li>
<li>эмбединги, полученные от нейросети BERT</li>
</ul>
<p>Модель хорошо работает из "коробки", но достаточно долго
обучается.<br />
По опыту прошлых проектов, подбор гиперпараметров не сильно влияет на
результаты модели.</p>
<p>Перебрём минимальное число гиперпараметров, которые могут немного
улучшить результат (l2 регуляризацию и количество итераций).</p>
<p><em>Используем GPU для ускорения работы.</em></p>
</div>
<div class="cell code" data-execution_count="79">
<div class="sourceCode" id="cb68"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>params_CatBoost <span class="op">=</span> { <span class="st">&#39;n_estimators&#39;</span>: [<span class="dv">1000</span>, <span class="dv">1200</span>],     <span class="co"># default 1000 </span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;l2_leaf_reg&#39;</span>: [<span class="dv">3</span>, <span class="dv">7</span>, <span class="dv">10</span>]         <span class="co"># default 3 </span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>                  }</span></code></pre></div>
</div>
<section id="21-catboost--очищенный-текст" class="cell markdown">
<h4>2.1 CatBoost + очищенный текст</h4>
</section>
<div class="cell code" data-execution_count="80">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>x_train_DF <span class="op">=</span> pd.DataFrame(x_train, columns<span class="op">=</span>[<span class="st">&#39;text&#39;</span>]) <span class="co"># техническое преобразование в датафрейм для работы модели</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>model_Cat_clean_text <span class="op">=</span> CatBoostClassifier(random_state<span class="op">=</span>RANDOM_STATE, eval_metric<span class="op">=</span><span class="st">&#39;F1&#39;</span>, task_type<span class="op">=</span><span class="st">&#39;GPU&#39;</span>)</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>model_Cat_clean_text, param_grid<span class="op">=</span>params_CatBoost, scoring<span class="op">=</span><span class="st">&#39;f1&#39;</span>, cv<span class="op">=</span><span class="dv">2</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>grid.fit(X<span class="op">=</span>x_train_DF, y<span class="op">=</span>y_train, text_features<span class="op">=</span>[<span class="st">&#39;text&#39;</span>], silent<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>best_params_Cat_clean_text <span class="op">=</span> grid.best_params_</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>best_metric_Cat_clean_text <span class="op">=</span> grid.best_score_</span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;-------------------------------------&#39;</span>)</span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Лучшая метрика F1 на кросс-валидации:&#39;</span>, best_metric_Cat_clean_text.__round__(<span class="dv">3</span>))</span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Лучшие гиперпараметры:&#39;</span>, best_params_Cat_clean_text) </span></code></pre></div>
<div class="output stream stdout">
<pre><code>-------------------------------------

Лучшая метрика F1 на кросс-валидации: 0.773
Лучшие гиперпараметры: {&#39;l2_leaf_reg&#39;: 3, &#39;n_estimators&#39;: 1200}
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Обучим модель с подобранными гиперпараметрами на всех обучающих
данных и засечём время.</p>
</div>
<div class="cell code" data-execution_count="81">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>best_model_Cat_clean_text <span class="op">=</span> CatBoostClassifier(random_state<span class="op">=</span>RANDOM_STATE, eval_metric<span class="op">=</span><span class="st">&#39;F1&#39;</span>, task_type<span class="op">=</span><span class="st">&#39;GPU&#39;</span>, <span class="op">**</span>best_params_Cat_clean_text)</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>best_model_Cat_clean_text.fit(x_train_DF, y_train, text_features<span class="op">=</span>[<span class="st">&#39;text&#39;</span>], silent<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time()</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>time_fit_Cat_clean_text <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Время обучения:&#39;</span>, time_fit_Cat_clean_text.__round__(<span class="dv">2</span>), <span class="st">&#39;c&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Время обучения: 18.0 c
</code></pre>
</div>
</div>
<section id="22-catboost--эмбединги-от-нейросети" class="cell markdown">
<h4>2.2 CatBoost + эмбединги от нейросети</h4>
</section>
<div class="cell code" data-execution_count="82">
<div class="sourceCode" id="cb73"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>model_Cat_embeddings <span class="op">=</span> CatBoostClassifier(random_state<span class="op">=</span>RANDOM_STATE, eval_metric<span class="op">=</span><span class="st">&#39;F1&#39;</span>, task_type<span class="op">=</span><span class="st">&#39;GPU&#39;</span>)</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>model_Cat_embeddings, param_grid<span class="op">=</span>params_CatBoost, scoring<span class="op">=</span><span class="st">&#39;f1&#39;</span>, cv<span class="op">=</span><span class="dv">2</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>grid.fit(X<span class="op">=</span>x_train_embedded, y<span class="op">=</span>y_train, silent<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>best_params_Cat_embeddings <span class="op">=</span> grid.best_params_</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>best_metric_Cat_embeddings <span class="op">=</span> grid.best_score_</span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;-------------------------------------&#39;</span>)</span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Лучшая метрика F1 на кросс-валидации:&#39;</span>, best_metric_Cat_embeddings.__round__(<span class="dv">3</span>))</span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Лучшие гиперпараметры:&#39;</span>, best_params_Cat_embeddings) </span></code></pre></div>
<div class="output stream stdout">
<pre><code>-------------------------------------

Лучшая метрика F1 на кросс-валидации: 0.918
Лучшие гиперпараметры: {&#39;l2_leaf_reg&#39;: 10, &#39;n_estimators&#39;: 1000}
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Обучим модель с подобранными гиперпараметрами на всех обучающих
данных и засечём время.</p>
</div>
<div class="cell code" data-execution_count="83">
<div class="sourceCode" id="cb75"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>best_model_Cat_embeddings <span class="op">=</span> CatBoostClassifier(random_state<span class="op">=</span>RANDOM_STATE, eval_metric<span class="op">=</span><span class="st">&#39;F1&#39;</span>, task_type<span class="op">=</span><span class="st">&#39;GPU&#39;</span>, <span class="op">**</span>best_params_Cat_embeddings)</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>best_model_Cat_embeddings.fit(x_train_embedded, y<span class="op">=</span>y_train, silent<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time()</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>time_fit_Cat_embeddings <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Время обучения:&#39;</span>, time_fit_Cat_embeddings.__round__(<span class="dv">2</span>), <span class="st">&#39;c&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Время обучения: 15.8 c
</code></pre>
</div>
</div>
<section id="сводные-данные-по-выбору-модели" class="cell markdown">
<h3>Сводные данные по выбору модели</h3>
<ol>
<li>Наилучшие результаты по метрике показала модель CatBoost с
использованием эмбедингов от предобученной нейросети.<br />
</li>
</ol>
<ul>
<li><strong>Остановим выбор на этой конфигурации</strong><br />
</li>
<li>Однако, стоит отметить, что решение времязатратное и требует
использования GPU</li>
</ul>
<ol>
<li>CatBoost c использованием встроенных средств векторизации показала
соответсвующую требованиям заказчика точность (0.77 по F1).</li>
</ol>
<ul>
<li>такое решение гораздо быстрее выбранного, более того самое быстрое
из рассмотренных при использовании GPU.<br />
</li>
<li>Возможно, даже без использования GPU время работы будет достаточно
оперативным.</li>
</ul>
<ol>
<li>Логистическая регрессия показывает хорошие результаты (0.77 - 0.88
по F1) при использовании эмбедингов и униграмм по TF-IDF.<br />
Однако использовать решения на основе данной модели не целесообразно,
т.к. нет преимуществ по сравнению с бустингом.</li>
</ol>
</section>
<div class="cell markdown">
<p>Рассчитаем общее время на подготовку всех сочетаний модель +
предобработка к инференсу. Учтём время на:</p>
<ul>
<li>лемматизацию</li>
<li>векторизация/получение эмбедингов</li>
<li>обучение модели с подобранными</li>
</ul>
<p><em>Очистка данных делается быстро (2-4 c) и используется в любом
случае - можно не учитывать.</em></p>
</div>
<div class="cell code" data-execution_count="84">
<div class="sourceCode" id="cb77"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>LogReg_tfidf_uni_score <span class="op">=</span> best_metric_LogReg_tfidf_uni.__round__(<span class="dv">3</span>)</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>LogReg_tfidf_uni_time <span class="op">=</span> <span class="bu">round</span>((time_lemmatization <span class="op">+</span> time_tfidf_uni <span class="op">+</span> time_fit_LogReg_tfidf_uni) <span class="op">/</span> <span class="dv">60</span>, <span class="dv">1</span>)</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>uni_text_vec_time <span class="op">=</span> <span class="bu">round</span>((time_lemmatization <span class="op">+</span> time_tfidf_uni) <span class="op">/</span> <span class="dv">60</span>, <span class="dv">1</span>)</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>LogReg_tfidf_di_score <span class="op">=</span> best_metric_LogReg_tfidf_di.__round__(<span class="dv">3</span>)</span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>LogReg_tfidf_di_time <span class="op">=</span> <span class="bu">round</span>((time_lemmatization <span class="op">+</span> time_tfidf_di <span class="op">+</span> time_fit_LogReg_tfidf_di) <span class="op">/</span> <span class="dv">60</span>, <span class="dv">1</span>)</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>di_text_vec_time <span class="op">=</span> <span class="bu">round</span>((time_lemmatization <span class="op">+</span> time_tfidf_di) <span class="op">/</span> <span class="dv">60</span>, <span class="dv">1</span>)</span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>LogReg_embeddings_score <span class="op">=</span> best_metric_LogReg_embeddings.__round__(<span class="dv">3</span>)</span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a>LogReg_embeddings_time <span class="op">=</span> <span class="bu">round</span>((time_fact_embeddings <span class="op">+</span> time_fit_LogReg_embeddings) <span class="op">/</span> <span class="dv">60</span>, <span class="dv">1</span>)</span>
<span id="cb77-11"><a href="#cb77-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-12"><a href="#cb77-12" aria-hidden="true" tabindex="-1"></a>embeddings_time <span class="op">=</span> <span class="bu">round</span>((time_fact_embeddings) <span class="op">/</span> <span class="dv">60</span>, <span class="dv">1</span>)</span>
<span id="cb77-13"><a href="#cb77-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-14"><a href="#cb77-14" aria-hidden="true" tabindex="-1"></a>Cat_clean_text_score <span class="op">=</span> best_metric_Cat_clean_text.__round__(<span class="dv">3</span>)</span>
<span id="cb77-15"><a href="#cb77-15" aria-hidden="true" tabindex="-1"></a>Cat_clean_text_time <span class="op">=</span> <span class="bu">round</span>((time_fit_Cat_clean_text) <span class="op">/</span> <span class="dv">60</span>, <span class="dv">1</span>)</span>
<span id="cb77-16"><a href="#cb77-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-17"><a href="#cb77-17" aria-hidden="true" tabindex="-1"></a>Cat_embeddings_score <span class="op">=</span> best_metric_Cat_embeddings.__round__(<span class="dv">3</span>)</span>
<span id="cb77-18"><a href="#cb77-18" aria-hidden="true" tabindex="-1"></a>Cat_embeddings_text_time <span class="op">=</span> <span class="bu">round</span>((time_fact_embeddings <span class="op">+</span> time_fit_Cat_embeddings) <span class="op">/</span> <span class="dv">60</span>, <span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="85">
<div class="sourceCode" id="cb78"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>score_table <span class="op">=</span> [[LogReg_tfidf_uni_score, LogReg_tfidf_uni_time, uni_text_vec_time],</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>               [LogReg_tfidf_di_score, LogReg_tfidf_di_time, di_text_vec_time],</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>               [LogReg_embeddings_score, LogReg_embeddings_time, embeddings_time],</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>               [Cat_clean_text_score, Cat_clean_text_time, <span class="dv">0</span>],</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>               [Cat_embeddings_score, Cat_embeddings_text_time, embeddings_time]</span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> pd.DataFrame(index<span class="op">=</span>[<span class="st">&#39;LOGISTIC REG УНИГРАММЫ&#39;</span>, <span class="st">&#39;LOGISTIC REG ДИГРАММЫ&#39;</span>, <span class="st">&#39;LOGISTIC REG ЭМБЕДИНГИ&#39;</span>, <span class="st">&#39;CATBOOST ОЧИСТ. ТЕКСТ&#39;</span>, <span class="st">&#39;CATBOOST ЭМБЕДИНГИ&#39;</span>], </span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>                     data <span class="op">=</span> score_table, columns<span class="op">=</span>[<span class="st">&#39;МЕТРИКА НА КРОСС-ВАЛИДАЦИИ&#39;</span>, <span class="st">&#39;ОБЩЕЕ ВРЕМЯ ПОДГОТОВКИ К ИНФЕРЕНС, МИН&#39;</span>, <span class="st">&#39;В Т.Ч. ВРЕМЯ ПРЕОБРАЗОВАНИЯ ТЕКСТОВ, МИН&#39;</span>])</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> score.sort_values(by<span class="op">=</span><span class="st">&#39;МЕТРИКА НА КРОСС-ВАЛИДАЦИИ&#39;</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a>score</span></code></pre></div>
<div class="output execute_result" data-execution_count="85">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>МЕТРИКА НА КРОСС-ВАЛИДАЦИИ</th>
      <th>ОБЩЕЕ ВРЕМЯ ПОДГОТОВКИ К ИНФЕРЕНС, МИН</th>
      <th>В Т.Ч. ВРЕМЯ ПРЕОБРАЗОВАНИЯ ТЕКСТОВ, МИН</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CATBOOST ЭМБЕДИНГИ</th>
      <td>0.918</td>
      <td>49.2</td>
      <td>48.9</td>
    </tr>
    <tr>
      <th>LOGISTIC REG ЭМБЕДИНГИ</th>
      <td>0.888</td>
      <td>50.9</td>
      <td>48.9</td>
    </tr>
    <tr>
      <th>CATBOOST ОЧИСТ. ТЕКСТ</th>
      <td>0.773</td>
      <td>0.3</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>LOGISTIC REG УНИГРАММЫ</th>
      <td>0.772</td>
      <td>4.8</td>
      <td>0.7</td>
    </tr>
    <tr>
      <th>LOGISTIC REG ДИГРАММЫ</th>
      <td>0.511</td>
      <td>24.6</td>
      <td>0.8</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="сводные-данные-по-выбору-модели" class="cell markdown">
<h3>Сводные данные по выбору модели</h3>
<ol>
<li>Наилучшие результаты по метрике показала модель CatBoost с
использованием эмбедингов от предобученной нейросети.<br />
</li>
</ol>
<ul>
<li><strong>Остановим выбор на этой конфигурации</strong><br />
</li>
<li>Однако, стоит отметить, что решение времязатратное и требует
использования GPU</li>
</ul>
<ol>
<li>CatBoost c использованием встроенных средств векторизации текста
показала точность (0.77 по F1) соответсвующую требованиям
заказчика.</li>
</ol>
<ul>
<li>такое решение гораздо быстрее выбранного, более того, самое быстрое
из рассмотренных при использовании GPU.<br />
</li>
<li>Возможно, даже без использования GPU время работы будет достаточно
оперативным.</li>
</ul>
<ol>
<li>Логистическая регрессия показывает хорошие результаты (0.77 - 0.88
по F1) при использовании эмбедингов и униграмм по TF-IDF.<br />
Однако использовать решения на основе данной модели не целесообразно,
т.к. нет преимуществ по сравнению с бустингом.</li>
</ol>
</section>
<section id="тестирование" class="cell markdown">
<h2>Тестирование</h2>
<p>Проверим модель на адекватность: сравним с бейзлайном - "дамми"
моделью, предсказывающей исходя из распределения ответов в
датасете.<br />
Сделаем "дамми" модель на тестовых данных, чтобы имитировать вновь
поступающие данные.</p>
</section>
<div class="cell markdown">
<p>Бэйзлан для проверки модели</p>
</div>
<div class="cell code" data-execution_count="86">
<div class="sourceCode" id="cb79"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>dummy_model <span class="op">=</span> DummyClassifier (strategy<span class="op">=</span><span class="st">&#39;stratified&#39;</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>dummy_model.fit(x_test, y_test)</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> dummy_model.predict(x_test)</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>dummy_test_score <span class="op">=</span> <span class="bu">round</span>(f1_score(y_true<span class="op">=</span>y_test, y_pred<span class="op">=</span>preds), <span class="dv">3</span>)</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Метрика дамми-модели:&#39;</span>, dummy_test_score)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Метрика дамми-модели: 0.104
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Для получения предсказаний сгенирируем эмбединги для тестовых
данных</p>
</div>
<div class="cell code" data-execution_count="87">
<div class="sourceCode" id="cb81"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>x_test_embedded <span class="op">=</span> func_get_embedings(x_test, run_on_gpu<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>GPU: NVIDIA GeForce RTX 3070 Laptop GPU is available. Running on GPU
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 777/777 [11:35&lt;00:00,  1.12it/s]
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Итоговая метрика лучшей модели</p>
</div>
<div class="cell code" data-execution_count="88">
<div class="sourceCode" id="cb84"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>final_preds <span class="op">=</span> best_model_Cat_embeddings.predict(data<span class="op">=</span>x_test_embedded)</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>final_f1_score <span class="op">=</span> f1_score(y_true<span class="op">=</span>y_test, y_pred<span class="op">=</span>final_preds)</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Итоговая метрика лучшей модели на тестовых даннных:&#39;</span>, <span class="bu">round</span>(final_f1_score, <span class="dv">3</span>))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Итоговая метрика лучшей модели на тестовых даннных: 0.911
</code></pre>
</div>
</div>
<section id="выводы-проекта" class="cell markdown">
<h2>Выводы проекта</h2>
</section>
<div class="cell markdown">
<p><strong>Данную задачу классификации эмоциональной окраски текстов
оптимально решать при помощи:</strong></p>
<ol>
<li>Эмбедингов от специализированной предобученной нейросети + модели
CatBoost; если доступна работа на GPU:<br />
</li>
</ol>
<ul>
<li><p>Решение позволяет получить очень высокую точность (0.9+ по
метрике F1) и превосходит требования заказчика (0.75+)</p></li>
<li><p>Ключевым является применение GPU - т.к. без этого ресурса время
подготовки к инференс может увеличится в 15-20 раз</p></li>
<li><p>Заказчику необходимо подсветить, что даже с использованием GPU
подготовка к инференс занимает длительное время.<br />
Это может создать трудности, если требуется часто переобучать
модель.</p></li>
</ul>
<ol>
<li>Модели CatBoost на текстах с минимальной предобработкой
(очисткой).<br />
Это хороший вариант при ограниченном времени GPU и необходимости частого
переобучения модели.</li>
</ol>
<ul>
<li><p>Такое решение является самым быстрым из рассмотренных</p></li>
<li><p>Обеспечивает приемлемый уровень точности (0.77+ по метрике F1),
соответсвующий требованиям заказчика</p></li>
<li><p>Решение является самым надёжным, т.к.:</p>
<ul>
<li>Оно простое, не требует отдельного этапа предобработки</li>
<li>Не требует использования сторонней предобученной на определённой
тематике нейросети</li>
</ul></li>
</ul>
<ol>
<li>Использование логистической регрессии и данных предобработанных по
технологии TF-IDF не целесообразно.<br />
Данная схема не показала конкурентных результатов ни по времении, ни по
точности.<br />
Возможно, у этой схемы есть шанс при работе только на CPU, если
подготовка к инференс по варианту 2. будет занимать длительное
время.</li>
</ol>
<p><strong>Возможные пути дальнейшего улучшения решения:</strong></p>
<ul>
<li>сделать тонкую предобработку текстов прописав отдельный аглоритм на
правилах на основе глубокого анализа текстов</li>
<li>более тонкий подбор гиперпараметров итоговой модели</li>
</ul>
<p><strong>Необходимо обсудить варианты 1. и 2. с заказчиком и выяснить
возможность выделения времени на для работы на GPU</strong></p>
</div>
</body>
</html>
